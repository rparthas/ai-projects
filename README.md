# AI Projects Collection

A curated collection of AI-powered applications built for learning and practical use. Each project demonstrates different aspects of AI integration, from document processing to workload analysis.

## ğŸš€ Projects Overview

### 1. [AI Workload Analyzer](./ai_workload_analyzer/)
**A Databricks-integrated AI workload analysis tool**

- ğŸ¤– **Databricks ChatAgent Integration**: Leverages Databricks agents for intelligent workload analysis
- ğŸ’¬ **Modern Chat Interface**: Beautiful Chainlit web interface for seamless interaction
- ğŸ“Š **SQL Query Analysis**: Analyzes and optimizes SQL queries with intelligent recommendations
- ğŸ”§ **UC Function Toolkit**: Integrates with Unity Catalog functions for enhanced capabilities
- ğŸ”„ **Streaming Responses**: Real-time streaming responses for better user experience

**Tech Stack**: `Python` â€¢ `Databricks` â€¢ `Chainlit` â€¢ `Claude 3.7 Sonnet` â€¢ `Unity Catalog`

### 2. [Local GPT with PDF Q&A](./local_gpt/)
**A local PDF document analysis and Q&A system**

- ğŸ“„ **PDF Document Q&A**: Upload multiple PDFs and ask questions about their content
- ğŸ” **Semantic Search**: ChromaDB vector database for intelligent document retrieval
- ğŸ§  **Context-Aware Responses**: Understands document context for accurate answers
- ğŸ’¾ **Local Processing**: Runs entirely on your machine using Ollama
- ğŸ”„ **Smart Chunking**: Intelligent text chunking with sentence-transformers

**Tech Stack**: `Python` â€¢ `Ollama` â€¢ `ChromaDB` â€¢ `Chainlit` â€¢ `sentence-transformers` â€¢ `PyPDF2`

### 3. [YouTube to Blog Converter](./yt_to_blog/)
**Transform YouTube videos into structured blog posts**

- ğŸ¥ **YouTube Transcript Extraction**: Automatic transcript extraction from YouTube videos
- ğŸ“ **AI-Powered Content Transformation**: Converts raw transcripts into professional blog posts
- ğŸ”— **Multiple URL Format Support**: Works with various YouTube URL formats
- ğŸ’¾ **Smart File Naming**: Automatic filename generation based on content
- ğŸ› ï¸ **Environment Configuration**: Easy model configuration via `.env` file

**Tech Stack**: `Python` â€¢ `Ollama` â€¢ `YouTube Transcript API` â€¢ `Markdown`

## ğŸ› ï¸ Prerequisites

### Common Requirements
- **Python 3.11+**
- **uv package manager** (recommended) - Install from [uv.astral.sh](https://uv.astral.sh/)
- **Ollama** (for local_gpt and yt_to_blog) - Download from [ollama.com](https://ollama.com)

### Project-Specific Requirements
- **AI Workload Analyzer**: Databricks workspace with appropriate permissions
- **Local GPT**: Ollama with a compatible model (e.g., `deepseek-r1:8b`)
- **YouTube to Blog**: Ollama with a compatible model (e.g., `llama3.2`)

## ğŸš€ Quick Start

### 1. Clone the Repository
```bash
git clone <repository-url>
cd ai-projects
```

### 2. Choose Your Project
Navigate to the project directory you want to use:

```bash
# For AI Workload Analyzer
cd ai_workload_analyzer

# For Local GPT
cd local_gpt

# For YouTube to Blog
cd yt_to_blog
```

### 3. Install Dependencies
```bash
uv sync
```

### 4. Configure Environment
Each project has its own setup requirements. Check the individual project README for specific configuration steps.

### 5. Run the Application
```bash
# For Chainlit-based projects (AI Workload Analyzer, Local GPT)
uv run chainlit run main.py

# For YouTube to Blog
uv run python main.py "https://www.youtube.com/watch?v=VIDEO_ID"
```

## ğŸ“ Project Structure

```
ai-projects/
â”œâ”€â”€ ai_workload_analyzer/     # Databricks workload analysis tool
â”‚   â”œâ”€â”€ main.py              # Chainlit app with Databricks integration
â”‚   â”œâ”€â”€ pyproject.toml       # Dependencies and config
â”‚   â”œâ”€â”€ README.md           # Detailed project documentation
â”‚   â””â”€â”€ env_example.txt     # Environment variables template
â”œâ”€â”€ local_gpt/              # Local PDF Q&A system
â”‚   â”œâ”€â”€ main.py             # Chainlit app with PDF processing
â”‚   â”œâ”€â”€ pyproject.toml      # Dependencies and config
â”‚   â”œâ”€â”€ README.md          # Detailed project documentation
â”‚   â””â”€â”€ chainlit.md        # Chainlit welcome screen
â”œâ”€â”€ yt_to_blog/            # YouTube to blog converter
â”‚   â”œâ”€â”€ main.py            # Main conversion script
â”‚   â”œâ”€â”€ test_main.py       # Unit tests
â”‚   â”œâ”€â”€ pyproject.toml     # Dependencies and config
â”‚   â””â”€â”€ README.md         # Detailed project documentation
â””â”€â”€ README.md            # This file
```

## ğŸ¯ Use Cases

### AI Workload Analyzer
- **Data Engineers**: Optimize SQL queries and data pipelines
- **Database Administrators**: Analyze workload performance and bottlenecks
- **Analytics Teams**: Get intelligent insights about data processing

### Local GPT
- **Researchers**: Analyze research papers and academic documents
- **Students**: Study from uploaded course materials and textbooks
- **Professionals**: Extract insights from business documents and reports

### YouTube to Blog
- **Content Creators**: Convert video content into written blog posts
- **Educators**: Create text-based resources from educational videos
- **Marketers**: Transform video content for multi-channel distribution

## ğŸ”§ Development

### Setting Up Development Environment
```bash
# Clone the repository
git clone <repository-url>
cd ai-projects

# Set up each project
for project in ai_workload_analyzer local_gpt yt_to_blog; do
    cd $project
    uv sync
    cd ..
done
```

### Running Tests
```bash
# Navigate to project directory
cd yt_to_blog

# Run tests
uv run python -m unittest test_main.py -v
```

### Contributing
1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“š Documentation

Each project has its own detailed README with:
- Comprehensive setup instructions
- API documentation
- Troubleshooting guides
- Advanced configuration options

## ğŸ› Troubleshooting

### Common Issues

**Ollama Connection Errors**
- Ensure Ollama is running: `ollama serve`
- Check if the model is downloaded: `ollama list`
- Verify model name in configuration

**Python Environment Issues**
- Use Python 3.11+ for all projects
- Prefer `uv` over `pip` for dependency management
- Check virtual environment activation

**Databricks Integration (AI Workload Analyzer)**
- Verify Databricks credentials and permissions
- Check Unity Catalog function accessibility
- Ensure model serving endpoint is available

## ğŸ¤ Support

For issues and questions:
- Check the individual project README files
- Review the troubleshooting sections
- Create an issue in the project repository
- Join relevant community discussions

## ğŸ“„ License

This project is open source and available under the MIT License.

---

**Note**: These projects are primarily created for learning AI development patterns and techniques. As they mature and become more production-ready, they may be moved to separate repositories.
